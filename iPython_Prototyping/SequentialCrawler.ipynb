{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal here is to build a sequential web scraper based off of the TTBID. I think that the simplest thing to do will just be to start with a basic easy date and then just increment until we get an error back. Since things are _supposedly_ sequential, we can interate easily. A good test will be to try for a small test range. It may also be worth trying to get those parallel scraping tools operational"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "TTB ID - This is a unique, 14 digit number assigned by TTB to track each COLA.  The first 5 digits represent the calendar year and Julian date the application was received by TTB. The next 3 digits tell how the application was received (001 = e-filed; 002 & 003 = mailed/overnight; 000 = hand delivered). The last 6 digits is a sequential number that resets for each day and for each received code.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "import datetime\n",
    "import pymongo\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn import cluster\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append(r'../ScrapingTools')\n",
    "from TTB_scraping import TTB_Scraper\n",
    "from time import sleep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_date = '01/30/2016'\n",
    "stop_date = '01/01/2017'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('logfile.txt', 'w')\n",
    "\n",
    "# Set up connection to mongodb\n",
    "client = pymongo.MongoClient() # Connect to default client\n",
    "db = client.TTB # Get a database (note: lazy evaluation)\n",
    "TTB = db.TTB # the actual collection\n",
    "\n",
    "# convert dates to datetime format\n",
    "date_start = datetime.datetime.strptime(start_date, '%m/%d/%Y')\n",
    "date_stop = datetime.datetime.strptime(stop_date, '%m/%d/%Y')\n",
    "\n",
    "# iterate over each date\n",
    "curr_date = date_start\n",
    "while (curr_date < date_stop):\n",
    "    print('Now on:  {}'.format(curr_date.strftime('%m/%d/%Y')))\n",
    "    # iterate over each recieve code\n",
    "    curr_reccode = 0\n",
    "    while curr_reccode <= 3:\n",
    "\n",
    "        # increment each sequence \n",
    "        cont_seq = True\n",
    "        curr_seqnum = 1\n",
    "        retry_count = 0\n",
    "        while cont_seq:\n",
    "            # prep the strings for the ttbid\n",
    "            jdate='{year}{day}'.format(year=curr_date.strftime('%y'), day=curr_date.strftime('%j'))\n",
    "            reccode='{:03d}'.format(curr_reccode)\n",
    "            seqnum='{:06d}'.format(curr_seqnum)\n",
    "\n",
    "            # prep the query\n",
    "            ttbid = '{jdate}{reccode}{seqnum}'.format(jdate=jdate, reccode=reccode, seqnum=seqnum)\n",
    "\n",
    "            query = TTB_Scraper(ttbid)\n",
    "            parsed_data = query.get_basic_form_data()\n",
    "\n",
    "            # if we got a valid response\n",
    "            if parsed_data:\n",
    "                query_data = {'_id': ttbid,\n",
    "                         'recieve_date':curr_date.strftime('%m/%d/%Y'),\n",
    "                         'recieve_code': reccode,\n",
    "                         'seq_num': seqnum}\n",
    "                \n",
    "                # concatinated data we will add to our database\n",
    "                output = {**query_data, **parsed_data}\n",
    "\n",
    "                curr_seqnum += 1\n",
    "                retry_count = 0\n",
    "                # Insert result into database\n",
    "                try:\n",
    "                    TTB.insert_one(output)\n",
    "                    #print('Successfully added: {}'.format(ttbid))\n",
    "                    f.write('{},1\\n'.format(ttbid))\n",
    "                except pymongo.errors.DuplicateKeyError:\n",
    "                    warnings.warn('_id: {ttbid} is already in database, skipping...'.format(ttbid=ttbid))\n",
    "            else:\n",
    "                # stick with this sequence\n",
    "                if retry_count < 3:\n",
    "                    curr_seqnum += 1\n",
    "                    retry_count += 1\n",
    "                else:\n",
    "                    cont_seq = False\n",
    "                f.write('{},0\\n'.format(ttbid))\n",
    "\n",
    "            sleep(0.1)\n",
    "        curr_reccode += 1\n",
    "    curr_date += datetime.timedelta(days=1)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "curr_reccode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ttbid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert(output['TTBID'] == output['_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up connection to mongodb\n",
    "client = pymongo.MongoClient() # Connect to default client\n",
    "db = client.TTB # Get a database (note: lazy evaluation)\n",
    "TTB = db.TTB # the actual collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    res = TTB.insert_one(output)\n",
    "except pymongo.errors.DuplicateKeyError:\n",
    "    warnings.warn('_id: {ttbid} is already in database, skipping...'.format(ttbid=ttbid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res.inserted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ttbid = 16004001000014\n",
    "query = TTB_Scraper(ttbid)\n",
    "data = query.get_basic_form_data()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_ttb_database(start_date, stop_date):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Getting data from the Mongo DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up connection to mongodb\n",
    "client = pymongo.MongoClient() # Connect to default client\n",
    "db = client.TTB # Get a database (note: lazy evaluation)\n",
    "TTB = db.TTB # the actual collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85213"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TTB.count() # number of elements in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = TTB.distinct('TTBID') # list of distinct TTBID's\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TTB.find_one('16001001000002')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can preint out some basic stats like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print collection statistics\n",
    "#print(db.command(\"collstats\", \"TTB\"))\n",
    "\n",
    "# print database statistics\n",
    "print(db.command({\"dbstats\": 1,  'scale': 1024}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate for one year's worth of entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(208/408) * 147073"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# WARNING: deletes database?\n",
    "#client.drop_database('TTB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mongo into Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following snippet _should_ turn every element of our mongodb into a list which is then parsed by pandas into a df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(TTB.find()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['TTBID'] = df['TTBID'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['TTBID'].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "by_status = df.groupby('Status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "approved_only = df.loc[df['Status'] == 'APPROVED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get list of all US states, convert to uppercase as that is what is used\n",
    "states = ['Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut', 'Delaware', 'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland', 'Massachusetts', 'Michigan', 'Minnesota', 'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire', 'New Jersey', 'New Mexico', 'New York', 'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania', 'Rhode Island', 'South Carolina', 'South Dakota', 'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington', 'West Virginia', 'Wisconsin', 'Wyoming']\n",
    "states = [state.upper() for state in states]\n",
    "\n",
    "us_state_abbrev = {'Alabama': 'AL','Alaska': 'AK','Arizona': 'AZ','Arkansas': 'AR','California': 'CA','Colorado': 'CO','Connecticut': 'CT','Delaware': 'DE','Florida': 'FL','Georgia': 'GA','Hawaii': 'HI','Idaho': 'ID','Illinois': 'IL','Indiana': 'IN','Iowa': 'IA','Kansas': 'KS','Kentucky': 'KY','Louisiana': 'LA','Maine': 'ME','Maryland': 'MD','Massachusetts': 'MA','Michigan': 'MI','Minnesota': 'MN','Mississippi': 'MS','Missouri': 'MO','Montana': 'MT','Nebraska': 'NE','Nevada': 'NV','New Hampshire': 'NH','New Jersey': 'NJ','New Mexico': 'NM','New York': 'NY','North Carolina': 'NC','North Dakota': 'ND','Ohio': 'OH','Oklahoma': 'OK','Oregon': 'OR','Pennsylvania': 'PA','Rhode Island': 'RI','South Carolina': 'SC','South Dakota': 'SD','Tennessee': 'TN','Texas': 'TX','Utah': 'UT','Vermont': 'VT','Virginia': 'VA','Washington': 'WA','West Virginia': 'WV','Wisconsin': 'WI','Wyoming': 'WY'}\n",
    "\n",
    "# capitalized versions\n",
    "abbrev_lookup=defaultdict(str)\n",
    "for k, v in us_state_abbrev.items():\n",
    "    abbrev_lookup[k.upper()] = v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38143"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_only = df.loc[df['OriginCode'].isin(states)]\n",
    "us_only = us_only.loc[df['Status'] == 'APPROVED']\n",
    "us_only['_id'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Img Proc on the subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def centroid_histogram(clt):\n",
    "    \"\"\"From pyimage search, gets us fraction of each color\"\"\"\n",
    "    # grab the number of different clusters and create a histogram\n",
    "    # based on the number of pixels assigned to each cluster\n",
    "    numLabels = len(np.unique(clt.labels_))\n",
    "    (hist, _) = np.histogram(clt.cluster_centers_, bins = numLabels)\n",
    "\n",
    "    # normalize the histogram, such that it sums to one\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= hist.sum()\n",
    "\n",
    "    # return the histogram (percentage described by each cluster)\n",
    "    return hist.reshape(numLabels,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dominant_colors(img, max_colors=10, n_init=25):\n",
    "    \"\"\"Uses k-means to find n_colors dominant colors, expects a PIL Image\"\"\"\n",
    "    thumbnail = Image.Image.copy(img)  # needed b/c thumbnail operates in place\n",
    "    thumbnail.thumbnail((128,128))  # reduce side to speed up\n",
    "\n",
    "    thumb = np.array(thumbnail)\n",
    "    \n",
    "    try:\n",
    "        # drop alpha, if it is present\n",
    "        if thumb.shape[2] == 4:\n",
    "            thumb = thumb[:,:,:3]\n",
    "    except IndexError:\n",
    "        # binary or gray scale image, replicate to make correct size\n",
    "        o_shape = thumb.shape\n",
    "        thumb = np.tile(thumb, 3).reshape((*o_shape, -1))\n",
    "        \n",
    "        \n",
    "    w, h, d = original_shape = tuple(thumb.shape)\n",
    "    assert d == 3\n",
    "    image_array = np.reshape(img, (w * h, d))\n",
    "\n",
    "    image_array_sample = shuffle(image_array, random_state=0)[:1000]  # take a random sample of 1000 points\n",
    "\n",
    "    rand_state = 0  # same randome state is used for repeatability\n",
    "\n",
    "    bestSilhouette = 0\n",
    "    for n_colors in range(2, max_colors):\n",
    "        clt = cluster.KMeans(n_clusters=n_colors, random_state=rand_state, n_init=n_init)\n",
    "        clt.fit(image_array_sample)\n",
    "        silhouette = silhouette_score(image_array_sample, clt.labels_, metric='euclidean')\n",
    "\n",
    "        # Find the best one\n",
    "        if silhouette > bestSilhouette:\n",
    "            bestSilhouette = silhouette\n",
    "            best_nClusters = n_colors;\n",
    "\n",
    "    clt = cluster.KMeans(n_clusters=best_nClusters, random_state=rand_state, n_init=n_init)\n",
    "    clusters = clt.fit(image_array_sample)\n",
    "    hist = centroid_histogram(clusters)\n",
    "\n",
    "    return [hist, cluster_labels.cluster_centers_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate over all domestic ID's, create new table for results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up connection to mongodb\n",
    "client = pymongo.MongoClient() # Connect to default client\n",
    "db = client.TTB # Get a database (note: lazy evaluation)\n",
    "TTB_labels = db.LabelImages # the actual collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5167"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TTB_labels.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry already present, skipping: 16003001000007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/datainc/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:709: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    }
   ],
   "source": [
    "for curr_id in us_only['TTBID'][77:]:\n",
    "    query = TTB_Scraper(curr_id)\n",
    "    [meta, imgs] = query.get_images()\n",
    "    output = {'_id': str(curr_id)}\n",
    "    for im_num, (metadata, img) in enumerate(zip(meta, imgs)):\n",
    "        [percentage, colors] = dominant_colors(img)\n",
    "        \n",
    "        colors = colors.clip(min=0, max=255)\n",
    "        hex_color = [matplotlib.colors.rgb2hex(rgb_color/255) for rgb_color in colors]\n",
    "        \n",
    "        output['img_{:02d}_label_type'.format(im_num)] = metadata[0]\n",
    "        output['img_{:02d}_label_url'.format(im_num)] = metadata[1]\n",
    "        \n",
    "        # add histograms using img.histogram()\n",
    "        \n",
    "        for num, (percent, color) in enumerate(zip(percentage, hex_color)):\n",
    "            output['img_{:02d}_color_frac_{:02d}'.format(im_num, num)] = percent[0]\n",
    "            output['img_{:02d}_color_hex_{:02d}'.format(im_num, num)] = color\n",
    "            \n",
    "    # Insert result into database\n",
    "    try:\n",
    "        TTB_labels.insert_one(output)\n",
    "        #print('Successfully added: {}'.format(ttbid))\n",
    "    except pymongo.errors.DuplicateKeyError:\n",
    "        #warnings.warn('_id: {ttbid} is already in database, skipping...'.format(ttbid=curr_id))\n",
    "        print('Entry already present, skipping: {}'.format(curr_id))\n",
    "    sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "curr_id= 16003001000008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '16001001000052'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 254.30569307,  252.82549505,  240.86262376],\n",
       "       [ 102.        ,  111.44444444,  102.33333333],\n",
       "       [ 205.81481481,  190.48148148,  171.55555556],\n",
       "       [ 225.33333333,    0.        ,   59.66666667],\n",
       "       [ 235.41269841,  235.32539683,  226.34126984]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colors.clip(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#e2e2e2', '#7f7f7f', '#fefefe', '#a4a4a4', '#c6c6c6']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hex_color = [matplotlib.colors.rgb2hex(rgb_color/255) for rgb_color in colors]\n",
    "hex_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 254.3478803 ,  252.67456359,  241.0074813 ],\n",
       "       [ 162.55      ,  108.85      ,   91.95      ],\n",
       "       [ 197.3902439 ,  172.14634146,  147.65853659],\n",
       "       [  78.42857143,   56.85714286,   56.57142857],\n",
       "       [ 230.67479675,  219.39837398,  200.16260163]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = Image.Image.copy(img)\n",
    "tmp.thumbnail((128,128))  # reduce side to speed up\n",
    "tmp = np.array(tmp)\n",
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_shape = tmp.shape\n",
    "np.tile(tmp, 3).reshape((*original_shape, -1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.2       ],\n",
       "        [ 0.13333333],\n",
       "        [ 0.06666667],\n",
       "        [ 0.33333333],\n",
       "        [ 0.26666667]]), array([[   0.29711752,    0.36141907,    0.37694013],\n",
       "        [ 178.22072072,  161.26801802,  159.99099099],\n",
       "        [ 120.89473684,  110.28947368,  108.63157895],\n",
       "        [  73.92307692,   68.38461538,   67.53846154],\n",
       "        [ 151.02439024,  136.29268293,  134.82926829]])]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dominant_colors(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = TTB_Scraper(curr_id)\n",
    "[meta, imgs] = query.get_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db.ProductData.find_one_and_update({'_id': curr_id},\n",
    "                                   {'$set': {'dcolor_frac': dcolor_frac},\n",
    "                                    '$set': {'dcolor_val': dcolor_val}}, upsert=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TTB.find_one({'_id': '16001001000001'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TTB.find_one_and_update()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:datainc]",
   "language": "python",
   "name": "conda-env-datainc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
